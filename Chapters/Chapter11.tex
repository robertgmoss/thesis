%************************************************
\chapter{Conclusions}\label{ch:conslusions}
%************************************************
\begin{flushleft}{\slshape    
    At the time, Nixon was normalizing relations with China.  
    I figured that if he could normalize relations, then so could I} \\ \medskip
    --- Edgar Codd
\end{flushleft}
%s
In this chapter we provide an outline of this thesis and the contributions of this work to Similarity Search.  We conclude with some suggestions as to how this work may be further extended.  

The aim of the work in this thesis is to give a better understanding of the role of structural similarity in search.  In chapter 1, we looked at the many different uses of similarity search; how it differs from traditional database systems; and a mathematical representation though which we work.  We outlined the common search query types; distance metrics; the principles of data storage; and finally a brief look at the challenges of high dimensional data.

In chapter 2, I haven't done anything yet!

Chapter 3 describes structural entropic distance and introduces the notion of structural similarity and complexity.  We show how this form of complexity has better semantics than Kolmogorov Complexity for similarity searching. we demonstrate that as a correlation metric in vector spaces it outperforms its only competitor cosine similarity in a number of ways and outputs more desirable results. 

In chapter 4, I haven't done anything yet!

Chapter 5 introduces the new concept of structural divergence as a generalisation of distance.  We look deeply at the properties of this function and explore the wider implications on similarity search.

In Chapter 6 we put divergence to the test with a series of experiments to determine its efficacy.  Here are the results of those experiments!

\section{Future work}
Some interesting questions presented themselves during the exposition of the divergence function.  These questions would serve as a solid foundation for future work!